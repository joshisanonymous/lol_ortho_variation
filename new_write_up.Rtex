%%%%%%%%%%%%%%%%%%%%%%%%
% Compile with XeLaTeX %
%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
  % Packages and settings
  \usepackage{fontspec}
    \setmainfont{Charis SIL}
  \usepackage[style=apa, backend=biber]{biblatex}
    \addbibresource{References.bib}
  \usepackage{hyperref}
    \hypersetup{colorlinks=true, allcolors=blue}
  \usepackage[group-minimum-digits=4, group-separator={,}]{siunitx}
  \usepackage{enumitem}

  % Document information
  \title{Orthographic variation of (lol)\footnote{
    Data and code available at \url{https://osf.io/mgdpu/}.
  }}
  \author{Joshua McNeill}
  \date{\today}

  % New commands
  \newcommand{\orth}[1]{$\langle$#1$\rangle$}
  \newcommand{\lexi}[1]{\textit{#1}}
  \newcommand{\gloss}[1]{`#1'}

\begin{document}
  <<settings_load_scripts, echo = FALSE>>=
  read_chunk("analysis.R")
  opts_chunk$set(echo = FALSE,
                 warning = FALSE,
                 message = FALSE,
                 results = "asis",
                 fig.height = 3,
                 fig.width = 5)
  @
  <<load_packages_functions_data>>=
  @
  \maketitle
  \begin{abstract}
    [TBD]
  \end{abstract}

  \section{Introduction}
    \label{sec:introduction}
    Studies of orthographic variation are not unheard of in sociolinguistics.
    This has been especially true since the widespread adoption of the internet as computer-mediated communication (CMC) presents both a wealth of relatively easily accessible data and social contexts that are less subject to overt social controls than what would have historically been the case for written forms as they had previously been largely relegated to educational and literary contexts.
    However, CMC studies and studies of orthographic variation in general have been focused mostly, though not always, either on situating CMC along a continuum between spoken language and older forms of written language or on the connection between phonology and spelling.

    With some notable exceptions, an area of orthographic variation that has not been explored as much is how it functions on its own terms, independent of phonology.
    As such, the aim of the present study is to give an in depth examination of the potential social and pragmatic associations of variants of an orthographic variable that cannot reasonably be linked to either spoken language or educational and literary writing: (lol) \gloss{laugh out loud}.

    \begin{enumerate}
      \item \Sexpr{lol[lol$'Token ID' == 840, "User"]}\footnote{
        Users whose tweets appear in the corpus used here have all been anonymized without concern for gender nor social identity.
      }: \Sexpr{lol[lol$'Token ID' == 840, "Text"]} \label{sent:lol}
      \item \Sexpr{lol[lol$'Token ID' == 3071, "User"]}: \Sexpr{lol[lol$'Token ID' == 3071, "Text"]} \label{sent:LOL}
      \item \Sexpr{lol[lol$'Token ID' == 2959, "User"]}: \Sexpr{lol[lol$'Token ID' == 2959, "Text"]} \label{sent:lololol}
    \end{enumerate}

    As tweets \ref{sent:lol}, \ref{sent:LOL}, and \ref{sent:lololol} show, there are various ways that (lol) can be spelled, ranging from all lowercase \orth{lol} to all uppercase \orth{LOL} to repeated characters that defy this item's origin as an acronym, as in \orth{lololol}.
    These three tweets alone also display numerous non-standard orthographic practices such as repeated punctuation, abbreviations, acronyms, and characters meant to be understood as some homophonous word or portion of a word, such as \orth{2} for \lexi{to}.
    Moreover, these tokens of (lol) also coincide with other non-standard features of English such as the negative concord in tweet \ref{sent:lol}.
    While any of these linguistic features could prove interesting to analyze, only (lol) is examined here.
    Specifically, we will look at (lol) as used on the social media platform Twitter, whether certain spelling variants are associated with certain Twitter communities or certain positions within communities and whether certain spelling variants are associated with particular sentiments.

    The rest of this introduction will be structured as follows.
    Section \ref{subsec:cmc} will cover the general nature of CMC and any special considerations that are applicable to the present study.
    Section \ref{subsec:orthographic_variation} will review work that has been done on orthographic variation.
    Finally, a thorough review of work that has been done on (lol), whether as a lexical or orthographic variable, will be presented in section \ref{subsec:previous_lol}.

    \subsection{Computer-mediated communication}
      \label{subsec:cmc}
      With the advent of the internet, many new mediums of communication have entered daily life, collectively referred to as CMC.
      Likewise, by the end of the 1990s, research focused on these new mediums began in ernest.
      For instance, \textcite{cherny_mud_1996} examined multi-user dungeons (MUDS), which are online, text-based, multiplayer games, whereas \textcite{herring_oral_1996} analyzed language in computer conferencing systems, which are perhaps best thought of as progenitors of discussion forums, and \textcite{paolillo_language_2001} looked at chatrooms on internet relay chat (IRC).
      These were all early mediums, and so studies have progressed to other mediums as they have been developed, which include instant messaging (IM) \parencite[e.g.,][]{baron_see_2004, tagliamonte_linguistic_2008}, the social media photo-sharing platform Instagram \parencite[e.g.,][]{stewart_anorexia_2017}, and both commonly and importantly for the present study, the social media micro-blogging platform Twitter \parencite[e.g.,][]{bamman_gender_2014, eisenstein_phonological_2013, hong_language_2011, ilbury_sassy_2020, jones_toward_2015, kim_sociolinguistic_2014}.
      \textcite{schneier_digital_2021} also looked at text messaging on cell phones, though his data included use of any communication application on a cell phone.

      \textcite{androutsopoulos_potentials_2008} described the goals of these researchers of CMC as fitting into two separate ``waves'',\footnote{
        This is not to be confused with \citeauthor{eckert_three_2012}'s (\citeyear{eckert_three_2012}) description of three ``waves'' of sociolinguistics, though there comparison is apt.
      } the first focused on the impact of the constraints placed on users of different CMC mediums on the language they produce, and the second focused more on analyses of what happens in CMC pragmaticly and sociolinguisticly (pp.~1-2), though one might also add that there has been a consistent interest in characterizing the relationship between CMC and both speech and older written mediums throughout both of these waves.
      A particularly useful tool for the present study -- and indeed any CMC study -- that was developed during the first wave is a typology for CMC mediums.

      In order to compare results from a study centered on Twitter, as we are doing here, with results from previous work, it is important to have a framework for classifying different mediums.
      As \textcite{paolillo_virtual_1999} recognized early on CMC is not identical to face-to-face conversation (p.~1).
      \textcite{herring_oral_1996} had previously gone even further, suggesting that CMC occurred in the absence of any field à la Halliday other than the text itself (pp.~45-46).
      \textcite{baron_see_2004} echoed these general sentiments, adding to them that the medium may change ``the character of language produced in that medium,'' leading her to formulate perhaps the most prevalent typological framework in CMC for mediums, which includes two dichotomous parameters: synchronicity versus asynchronicity, and one-to-one versus one-to-many interactions (p.~398).
      The first parameter, synchronicity versus asynchronicity, refers to whether there is a reasonable expectation between the interlocutors that messages will be received and responses made immediately, as if in a face-to-face conversation.
      The second parameter, one-to-one versus one-to-many interactions, refers to whether locutors are sending messages that are meant to be received either by one person or by many people.

      \citeauthor{baron_see_2004}'s (\citeyear{baron_see_2004}) typological framework for CMC is useful for understanding how comparable data produced through different mediums is as there may be different limitations placed on the forms of messages.
      For instance, \textcite{baron_see_2004} suggested that chatrooms, MUDs, and IM are all synchronous CMC mediums, whereas text messaging is asynchronous as one may not expect immediate replies to text messages (p.~398).
      The implication is that data collected from chatrooms and IM are more comparable than data collected from chatrooms and text messages.

      Indeed, there are clear examples of the synchonocity or asynchronicity of a medium having an effect on how conversations progress.
      \textcite{baron_see_2004} herself noted a phenomenon in instant messaging in which multiple topics overlap as a result of both interlocutors being able to construct messages simultaneously without interrupting each other (p.~400), which would not happen in a less synchronous medium such as e-mail.
      Somewhat relatedly, she observed a prevalence of multiturn sequences, where each sent message is considered a turn.
      \textcite{baron_see_2004} argued that interlocutors face pressure to break up their messages into multiple shorter turns in order to hold the floor (p.~417), the idea being that, since messages are not seen until sent, longer single turn messages provide more time for the other party to chime in before the whole statement is ready to be sent.
      These sorts of phenomena suggest that one must be cautious when comparing the language used in one CMC medium versus another.

      However, the boundaries between what should be considered synchronous and asynchronous are somewhat fuzzy.
      While chatrooms would presumably yield situations where interlocutors immediately reply to each other, this is not necessarily the case.
      IRC still exists today, though the way it is used may have changed over the last 20 years.
      For instance, at the time of this writing, the chatroom \#nlp on the freenode network, which offers discussion and help with natural language processing, has a topic that states that it may take two to three hours to get a response to a question.
      The reason is that it is typical to be connected to an IRC chatroom without monitoring it closely, making it less synchronous than might be expected.
      Indeed, \textcite{baron_see_2004} herself acknowledged that IM users in her data were sometimes multitasking while connected and so did not always respond immediately (p.~419).
      Even in clearer cases of asynchronicity, such e-mail, there is still some imperfection in the classification as many people now own cell phones that receive e-mail notifications instantly wherever they are, allowing for relatively quick responses, though quick responses are not necessarily expected.
      This parameter is still useful, of course, since a medium can be thought of as more or less synchronous in terms of expectations -- in our case, Twitter is relatively asynchronous but can be used from a cell phone that provides immediate notifications still -- but there are caveats to keep in mind.

      It is also important to consider the audience for messages.
      \citeauthor{baron_see_2004}'s (\citeyear{baron_see_2004}) framework accounts for this with the one-to-one versus one-to-many parameter.
      Protypical examples of each might be e-mail for the former and blogs for the latter, although here again one finds some fuzziness in the categorization.
      While e-mail might typically be a one-to-one medium, one-to-many messages are not unknown.

      This same difficulty in categorization is present on Twitter, as well, where the most common sort of messages may be one-to-many, but there exist public directed messages and private directed messages.
      Again, the parameter here is still useful, but in this case, there is also an alternative: \citeauthor{bell_language_1984}'s (\citeyear{bell_language_1984}) audience design framework.
      Indeed, \textcite{pavalanathan_audience-modulated_2015} employed this framework on Twitter, which yielded interesting results, as will be discussed further in the \nameref{sec:methods} section.
      Likewise, the audience design framework would have been useful when \textcite{auer_style_2008} had found ``hip-hop slang'' to be used more on German hip-hop discussion forums than on German hip-hop homepages and online magazines (p.~293).
      Both of these venues are indeed one-to-many when approached from \citeauthor{baron_see_2004}'s (\citeyear{baron_see_2004}) typology, but the results are not the same.
      One could instead argue from the audience design framework that the audience for a homepage or magazine is far broader than for a discussion forum, leading to more standard language.
      What is to be taken away from this is that audience appears to impact the character of the language produced on Twitter, which can inform how we interpret results in the present study.

    \subsection{Orthographic variation}
      \label{subsec:orthographic_variation}
      From early on in CMC research, it has been acknowledged that CMC is not only different from face-to-face language, as \textcite{paolillo_virtual_1999} recognized, but that it is also different from older forms of writing.
      Indeed, \textcite{tagliamonte_linguistic_2008}, speaking of instant messaging, described it as a ``hybrid register'', somewhere between speech and older forms of writing (p.~5).
      Part of this hybridity perhaps stems from CMC taking place outside of the auspices of social institutions, such as schools and book publishers, that extert overt social control on what is acceptable.
      This makes CMC a fruitful area for locutors to creatively manipulate linguistic features to various ends, one of those features being the focus of the present study: orthography.
      It is thus useful to review the literature on orthographic variation to better understand what functions and associations it has, as that is what we would like to analyze for (lol).
      We group these under four broad categories: those related to 1) grammar, 2) audience, 3) community or subsets of a community, and 4) pragmatics.

      Before moving on to the possible functions and associations of orthographic variation, it should first be noted that orthographic variation is unlikely to simply be the result of poor spelling capability.
      \textcite{varnhagen_lol_2010}, in their examination of instant messaging, compared participants scores on spelling tests to their use of non-standard spellings in IM.
      They found no relationship between the two, suggesting that non-standard spelling is not the result of a poor grasp of standard spelling.
      In fact, they found that non-standard spelling norms were acquired quite readily.
      For example, \orth{shoulda} \gloss{should have} was found but never forms like \orth{shulda} \parencite[p.~731]{varnhagen_lol_2010}.
      The implication is that non-standard spellers may actually be very good spellers if the qualification of ``good'' in this case is defined as \gloss{accurately follows norms}.

      \subsubsection{Connection to grammar}
        \label{subsubsec:connect_grammar}
        It is not unusual for variant spellings to be constrained by grammar.
        A very standard and overt example of this comes from French verbs.
        For most verbs, the singular first, second, and third person present forms of verbs are phonetically identical, yet the written forms vary anyway to agree with the subject.
        \lexi{Parler} \gloss{to speak} is pronounced [paʀl] for all three singular subjects in perhaps most varieties of Hexagonal French,\footnote{
          French spoken in France.
        } but is written \orth{parle} for first and third person and \orth{parles} for second person.
        It is thus useful to consider other potential grammatical constraints on orthographic variation.

        One such case can be found in Hinrichs and White-Sustaíta's (2011) work on Jamaican Creole, which has English as its superstrate.
        They found that speakers of the language living outside of Jamaica would vary between spellings such as \orth{mi} and \orth{me}, both pronounced [mi], based on the syntactic function within the sentence, using the former as the subject pronun and the latter in all other cases.
        Hinrichs and White-Sustaíta (2011) argued that \orth{mi} was limited to the subject pronoun function because this was a stereotypical feature of Jamaican Creole as English would have \lexi{I} in these cases.
        However, they note that it could also be said that this variation indicates a complex relationship to English and perhaps non-Creole-speakers \parencite[Hinrichs and White-Sustaíta 2011, as cited in][p.~165]{eisenstein_systematic_2015}, making it not only grammatical constrained but possibly socially motivated.

        Hinrichs and White-Sustaíta's example from Jamaican Creole is somewhat similar to \citeauthor{tatman_im_2016}'s (\citeyear{tatman_im_2016}) report of variation between \orth{work} and \orth{werk} among drag queens online.
        She compared collocations for the two and found that \orth{werk} was typically used to express approval and \orth{work} to express the more typical notion of doing work, leading her to conclude that these are in fact different lexical items \parencite[pp.~163-164]{tatman_im_2016}.
        Determing whether this involved two lexical items versus one polysemous lexical item is well beyond the scope of the present study, and it would be admittedly a weak argument to claim that this variation is purely constrained by syntax, but there is enough in this example to make the more grammatical interpretation possible, wherein \orth{werk} is limited to particular syntactic positions.

        Clearer examples of grammatically constrained orthographic variation come from \citeauthor{eisenstein_systematic_2015}'s (\citeyear{eisenstein_systematic_2015}) work on Twitter.
        He examined two orthographic variables that, on the surface, would appear to have a spoken phonological connection: (ing) as \orth{ing} or \orth{in}\footnote{
          This presumably would include \orth{in'}, though \textcite{eisenstein_systematic_2015} does not explicitly give that variant.
        } and (th) fortition, which he refers to as \lexi{th}-stopping.
        In both cases, grammatical constraints were found.
        The variable (ing) was more likely to be realized as \orth{in} for verbs (p.~176), and the variable (th) was more likely to be realized as a glyph \orth{d} when the spoken form would typically be voiced as opposed to having it realized as \orth{t} when the spoken form would be voiceless \parencite[pp.~170-171]{eisenstein_systematic_2015}.
        There were other social factors found to be constraining these variables, but there is a strong argument here that linguistics factors were important for both.

      \subsubsection{Connection to audience}
        \label{subsubsec:connect_audience}
        Another constraining factor that \textcite{eisenstein_systematic_2015} found for the realization of (ing) was the audience.
        As was already discussed in section \ref{subsec:cmc}, the intended or expected audience for a message seems to have an impact or the character of language used on CMC just as it does in spoken language, but the examples from \textcite{pavalanathan_audience-modulated_2015} and \textcite{auer_style_2008} were related to lexical variation instead of orthographic variation.
        \textcite{eisenstein_systematic_2015}, on the other hand, found this some relationship for orthographic variation where \orth{in} was the more frequent variant for @-messages on Twitter, meaning messages that were directed at a particular user instead of posted as general public statements (p.~176).

        Additionally, \textcite{auer_style_2008} did generally look for respellings in his data, as well, also finding evidence of the importance of audience.
        On the German hip-hop website webbeatz.de, for example, he noted more colloquial spellings (i.e., those non-standard spellings that are related to colloquial speech) than in other areas of the same site (p.~297).
        The implication is that discussion forums are expected to be read by the more engaged members of the community whereas general web pages are more likely to be viewed by broader passers by, so to speak.

      \subsubsection{Connection to community membership}
        \label{subsubsec:connect_community}
        Perhaps the most common associations examined for linguistic variables in variationist studies are associations between variants and particular communities or particular segments of communities, and indeed, these associations exist for orthographic variation.
        For instance, Sebba (1998) examined spelling in British Creole and suggested that non-standard spellings are used both because they distance the language from its English superstrate and because there is no orthographic norm for British Creole.
        The very idea of non-standard in this case, then, is \gloss{not as would be done for English}.
        Sebba (1998) provided examples such as \orth{Jameka} and \orth{kool} where standard English orthography would have \orth{Jamaica} and \orth{cool} \parencite[as cited in][p.~515]{androutsopoulos_non-standard_2000}.
        The idea is not simply to buck the superstrate but to make a statement against speakers of the superstrate,\footnote{
          Of course, it is possible that many British Creole speakers are also English speakers, but the presumption is that speakers identities are bound up in their language preferences.
        } to assert an independent identity from those speakers.

        \textcite{androutsopoulos_potentials_2008} also presented an example of using a particular orthographic variant on German hip-hop websites to signal membership in the particular community.
        In this case, \orth{z} would be written where \orth{s} was expected.
        What makes this example's importance particularly clear is that \textcite{androutsopoulos_potentials_2008} quoted one of his informants as explicitly claiming that such \orth{z} signaled an extreme dedication to hip-hop (pp.~12-13).
        It appears, then, that orthographic variation can be quite salient.

        \citeauthor{eisenstein_systematic_2015}'s (\citeyear{eisenstein_systematic_2015}) once again proves useful in also showing community membership can be a determining factor in orthographic variation.
        When examining (ing), he found that tweets emanating from US counties with high population density and/or high Black populations were more likely to have tokens of \orth{in} than those emanating from other counties \parencite[p.~176]{eisenstein_systematic_2015}.
        It is important to note that he did not know the claimed racial identities of these Twitter users, but the presumption is that they are likely to identify as Black or to at least be highly exposed to those who identify as Black in their daily lives.

        \citeauthor{eisenstein_systematic_2015}'s (\citeyear{eisenstein_systematic_2015}) finding also begins to highlight the important of geographic location.
        Indeed, one should not confound virtual communities, those formed through consistent interaction online around shared interests \parencite[Castells 2000, as cited in][p.~283]{auer_style_2008}, and physically centered communities, but this does not mean that a connection between the two is impossible.
        As \textcite{mcneill_lol_2018} showed for virtual communities and geographically defined communities in the Maritime Provinces of Canada, those who live near each other tend to converge online, as well (pp.~88-91).

        As such, \textcite{jones_toward_2015} found that the choice of non-standard spelling between \orth{nuttin} and \orth{nun} on Twitter, both attempts to represent \lexi{nothing} spoken with an intervocalic glottal stop, was constrained by geographic.
        Those tweeting from the north in the US preferred \orth{nuttin}, and those tweeting from the south in the US preferred \orth{nun} (p.~424).
        It might thus be expected that northerners and southerners form separate virtual communities, as well, where different norms are established, as the spoken pronunciations in both areas would be the same.

        There are also cases, though, where one might say that a virtual location is the constraining factor. Cherny (1995) offered somewhat anecdotal evidence of this in the early days of the internet.
        She analyzed the use of \orth{u} and \orth{r} for \orth{you} and \orth{are}, respectively, finding that while these non-standard spellings did appear in MUDs, players of MUDs considered them to be forms that originated in IRC chatrooms \parencite[as cited in][p.~2]{paolillo_virtual_1999}.
        If MUDs and IRC chatrooms are conceptualized as separate locations, then a important determinant here was likely virtual location.

        Age also appears to be a determinant for the realization of orthographic linguistic variables.
        \textcite{schnoebelen_you_2012} analyzed the use of different emoticons, faces essentially drawn using alphanumeric characters.
        He looked particularly closely at those that included noses, such as \orth{:-)}, versus those that did not, such as \orth{:)}.
        He found that noseless emoticons were preferred more by older users of Twitter more so than younger users, though noseless emoticons were also associated with users who disregarded various orthographic standards by doing things such as repeating letters or leaving out apostophes (pp.~122-124).

        \textcite{baron_see_2004} also analyzed emoticons in instant messaging with the addition of analyzing abbreviations and acronyms that she considered unique to CMC.
        She found that emoticons were almost exclusively limited to female participants in her data (pp.~415-416).
        This result was reproduced in \citeauthor{varnhagen_lol_2010}'s (\citeyear{varnhagen_lol_2010}) work on instant messaging, though the results were not as quite as lopsided as in the earlier study (pp.~728-729).

      \subsubsection{Connection to pragmatics}
        \label{subsubsec:connect_pragmatics}
        \textcite{androutsopoulos_non-standard_2000} long ago acknowledged that orthographic variants can perform pragmatic work.
        He argued that they ``signal certain attitudes or evoke certain frame of interpretation by establishing a contrast to the text's spelling regularities or to the default spelling of a linguistic item'' \parencite[p.~517]{androutsopoulos_non-standard_2000}.
        An example of such a contrast can be found in his study of German punk fanzines, essentially low budget magazines made by enthusiasts.
        \textcite{androutsopoulos_non-standard_2000} noted that the typical spelling of the term \lexi{fanzine} was \orth{fanzine}, which in fact bucks against standard German spelling in which all nouns are capitalized.
        Nevertheless, this was the established norm within fanzines themselves.
        As a result, those familiar with the medium would sometimes produce hypothetical quotations from Germans who were not familiar that included the spelling \orth{Fähnziehn}, much more in line with standard German orthography, with the result being mockery of the latter's ignorance \parencite[p.~526]{androutsopoulos_non-standard_2000}.

        The example of a pragmatic factor in the realization of orthographic variables given in this section as well as the examples of other factors from the preceding sections provide some insight into what the possible determinants variables are.
        Unsurprisingly, the range is as broad as that which can be found for linguistic variables in spoken language.
        While it will not be possible to look at each and every factor in analyzing (lol) due to the limitations of what we know about Twitter users without directly interacting with them, we will endeavor to include as many factors as possible in line with the exploratory nature of this study.

    \subsection{Previous work on (lol)}
      \label{subsec:previous_lol}
      The orthographic variable being analyzed in the present study is (lol), which at least originally was an acronym that stood for \gloss{laugh out loud}.
      This acronym is thought to have originated in English language chatrooms in the 1980s \parencite[McCulloch 2019, as cited in][p.~4]{schneier_digital_2021}.
      However, it has found its way into other languages, as well.
      \textcite{lienard_les_2014} documented (lol) being used by early adopters of the internet in Mayotte, an island nation near Reunion in Africa.
      What is notable about this case is that the internet had only effectively been accessible starting in 2012 (p.~154), and English was not a local language nor an official language in Mayotte, those being Shimaroe and Kibushi for the local languages and French for the official language (p.~158).
      Likewise, \textcite{mcneill_lol_2018} documented significant use of \lexi{lol} in what would otherwise be viewed as French-language tweets on Twitter.
      It appears possible then that (lol) has become something of an internet-language acronym rather than an English-language acronym, though almost all the work done on it has been focused on English.

      Despite its penetration even into other languages, \lexi{lol} is not overall a frequent lexical item when compared to other lexical items.
      In \citeauthor{baron_see_2004}'s (\citeyear{baron_see_2004}) IM data, \lexi{lol} made up only 0.6\% of the total words.
      Similarly, in \citeauthor{tagliamonte_linguistic_2008}'s (\citeyear{tagliamonte_linguistic_2008}) IM data, it made up 0.41\% of the words, and 0.35\% in \citeauthor{schneier_digital_2021}'s (\citeyear{schneier_digital_2021}) cell phone data.
      \textcite{schneier_digital_2021} also found \lexi{lol} to be most frequent turn-initially and turn-finally (p.~14).
      This low overall frequency might be damning for quantitative analyses, but it is perfectly in line with Zipf's law, which claims that the most frequent lexical items in any corpus will be exponentially more frequent than those ranked even only slightly lower in frequency, and indeed \lexi{lol} is highly frequent when compared to other as far as content words go (\citeauthor{baron_see_2004}, \citeyear[p.~412]{baron_see_2004}; \citeauthor{mcneill_lol_2018}, \citeyear[p.~60]{mcneill_lol_2018}), rendering it analyzable in a quantitative fashion.

      \subsubsection{As a lexical variable}
        \label{subsubsec:lexical_lol}
        Previous analyses of \lexi{lol} have by and large treated it as a lexical variable as opposed to an orthographic variable.
        While the current study aims to present an orthographic analysis, the results from lexical analyses provide some context for better understanding variant spellings.
        What those results repeatedly suggested was that \lexi{lol} is employed primarily for pragmatic purposes.

        \textcite{baron_see_2004} included \lexi{lol} in her study of gender in instant messaging, though she did not draw any conclusions about it being constrained by gender.
        Instead, she aruged that it functioned as a ``phatic filler'' used to show engagement in the same way as lexical items such as ``\lexi{OK}, \lexi{cool}, or \lexi{yeah}'' \parencite[p.~412]{baron_see_2004}.
        Likewise, \textcite{tagliamonte_linguistic_2008} described \lexi{lol} ``as a signal of interlocutor involvement,'' specifically contrasting this interpretation with items such as \lexi{haha} and \lexi{hehe}, which they described as simply forms of laughter (p.~11).
        A non-pragmatic constraint was also found, however, in that \lexi{lol} was more common among young user of instant messaging than older users \parencite[p.~13]{tagliamonte_linguistic_2008}.

        \textcite{schneier_digital_2021} also gave a lexical treatment of \lexi{lol}, though he did not wash \lexi{lol} of its connection to laughter as others had done.
        He argued instead that laughter in spoken conversation has pragmatic functions itself, specifically that it helps mitigate face threatening acts\parencite[p.~5]{schneier_digital_2021}.
        Shorter keybursts for \lexi{lol} at the beginning of turns led him to this conclusion as one would want to very quickly respond when attempting to help one's interlocutor save face \parencite[pp.~17-18]{schneier_digital_2021}.
        It was also argued that \lexi{lol} goes beyond the functions of laughter in spoken language in that it also helps to coordinate turn taking \parencite[p.~5]{schneier_digital_2021}.

      \subsubsection{As an orthographic variable}
        \label{subsubsec:orthographic_lol}
        While (lol) shows up in analyses as a lexical variable, to date, no research has analyzed what the constraints on and functions of orthographic variants of it are.
        That said, some work on orthographic variation in CMC has been done for other variables the results of which can be suggestive for how (lol) works.

        A rather obvious difference between the written language mode and spoken language mode is that the latter has a clear prosodic dimension nor a gestural dimension in the former that can be used for pragmatic purposes such as turning an utterance into a question or expressing disbelief.
        However, there are arguably orthographic tools available to cover these functions such as capitalization and reduplication.
        This phenomenon of using the unique tools that a medium offers to cover the functions of the tools that it lacks can be referred to as paralinguistic restitution \parencite[Thurlow and Brown 2003, as cited in][p.~3]{schneier_digital_2021}.

        Along the same lines, the idea of affective lengthening has also been proposed, which is essentially the reduplication of individual typed characters for pragmatic effect \parencite[pp.~117-118]{schnoebelen_you_2012}.
        Indeed, just such lengthening is readily apparent in the tweets collected for the present study as can be seen in tweet \ref{sent:looool}, though an argument for what exact function this has or whether it even represents a pragmatic function has yet to be made.

        \begin{enumerate}[resume]
          \item \Sexpr{lol[lol$'Token ID' == 4289, "User"]}: \Sexpr{lol[lol$'Token ID' == 4289, "Text"]} \label{sent:looool}
        \end{enumerate}

        Not all studies of orthographic variation in CMC propose that variants are linked to pragmatics.
        \textcite{stewart_anorexia_2017}, for example, analyzed variation in the spelling of a banned hashtag on Instagram that was used for posts that treated anorexia as a positive condition.
        Instagram users developed variants to get around the ban, and these variants became more and more disconnected from the original as measured using Levenshtein distance \parencite[p.~4]{stewart_anorexia_2017}.
        It was found that newcomers to this Instagram community preferred the variants with the greatest distance from the original \parencite[pp.~5-6]{stewart_anorexia_2017}, suggesting perhaps that the community was stratified by something akin to age and that these variants were not in contrast serving any pragmatic functions.

        There is thus reason to suspect that spelling variation in (lol) may be either socially constrained or serving pragmatic functions.
        As a result, the primary research question of the present study is the following:
        \begin{itemize}
          \item[RQ] What are the social constraints and/or pragmatic function of the orthographic variable (lol)?
        \end{itemize}
        This is naturally a rather open-ended exploratory question given the lack of research on this particular variable, meaning results will have as much precision as possible, but more research will likely be needed.

  \section{Methods}
    \label{sec:methods}
    The corpus used for this study is a collection of tweets from Twitter.
    As such, this section will briefly discuss some characteristics of Twitter along with how the tweets were scraped in section \ref{subsec:data_collect}.
    This will be followed by discussion of the information information that was coded for each token in section \ref{subsec:coding}.
    As some of the social network analysis techniques involved in the coding are fairly novel in sociolinguistics, a greater amount of detail will be provided in the coding section.
    Finally, the statistics to be used to analyze the detail will be discussed in section \ref{subsec:statistics}.

    \subsection{Data collection}
      \label{subsec:data_collect}
      The social media platform Twitter offers great opportunities for the study of language but also presents its own special challenges for research.
      In \citeauthor{herring_oral_1996}'s (\citeyear{herring_oral_1996}) early work on CMC, he decided to collect data from a computer conferencing system as these systems involved ``open'' discussions that carried fewer ethical concerns than CMC mediums that users expect to be private (p.~31).
      This is also true of Twitter, which allows users to make their accounts private but is by and large used as a form of open public discourse.
      Messages, referred to as tweets, are posted to users' timelines to be read by other users who explicitly follow the posters.
      At the time of the data collection for this study, tweets were limited to 140 charaters, though that number has since been increased to 280.

      Tweets can also be directed at specific users, in which case this form of CMC begins to resemble face-to-face conversation in some ways, as has been noted \parencite[e.g.,][p.~31]{danescu-niculescu-mizil_mark_2011}.
      There are some key differences, however.
      First, only a quarter of Twitter users have been found to hold conversations \parencite[Java et al. 2007, as cited in][p.~1]{danescu-niculescu-mizil_mark_2011}, defined as sending directed tweets back and forth, though this proportion varies depending on the language being used \parencite{hong_language_2011}.
      Second, and relatedly, conversations may or may not be synchronous, particularly in today's world where Twitter is commonly accessed via smartphones that can provide instant notifications of incoming messages wherever a user may be.
      Lastly, and most obviously, Twitter involves only written communication, which both removes access to some methods of expression such as gestures and prosody but also introduces new methods such as punctuation, spelling, and images.

      The particular Twitter corpus used for this study was originally collected for a study looking at (lol) as a lexical variable as used in French tweets originating in the Maritime Provinces of Canada \parencite{mcneill_lol_2018}.
      Tweets were collected continuously between January 8th, 2017 and February 8th, 2017 using what was at the time referred to as the spritzer level of access to Twitter's API, which allows samples to be taken from 1\% of all public tweets (as opposed to gardenhose access at 10\% and firehose at 100\%).
      Collecting samples of tweets is essentially identical to using Twitter's search bar, which allows users to specify geographic regions, languages, dates, and so on.
      The following search string was used for the \textcite{mcneill_lol_2018} corpus:
      \begin{itemize}
        \item[] geocode:46.0878,-64.7782,200mi exclude:retweets exclude:links
      \end{itemize}

      The first parameter of the search string uses latitude and longitude to target the Maritime Provinces.
      The second parameter excludes retweets, which involve one user repeating another users tweet in the former's own timeline and so does not count as language use by the former.
      The last parameter excludes tweets that contain links as these are more likely to be posts from commercial accounts as opposed to language use from regular users.
      Both of these exclusions are common practice when working with Twitter data \parencite[e.g.,][p.~199]{pavalanathan_audience-modulated_2015}.

      This method of scraping Twitter for data resulted in a corpus made up of 1,274,233 tweets, by and large in English, though not all of these were used in the original study nor will they all be used in the present study.
      In order to limit the effects of variable audiences for tweets, this initial set of tweets was filtered so as to include only directed tweets.
      This increases the likelihood of the message being part of a conversational interaction and ensures that it was intended for the community to which the poster belonged.

      Indeed, audience is a constraining factor in language variation on Twitter, so including tweets with different types of audiences (i.e., individuals versus the public in general) is an important step.
      African-American English features used by gay White men from England on Twitter were more likely to occur in tweets directed at other such users rather than in broadcast tweets \parencite[p.~256]{ilbury_sassy_2020}.
      The fact of being directed or not has also been found to constrain the presence of \orth{g} in the (ing) orthographic variable \parencite[p.~176]{eisenstein_systematic_2015} as well as lexical choices \parencite{pavalanathan_audience-modulated_2015}.

      Filtering the data down to only directed tweets resulted in a corpus of 307,878 tweets, but as the focus was only on French language tweets in the original study, this number was further filtered down to include only those Twitter communities that contained French tweets, resulting in \Sexpr{length(levels(factor(tweets$Community)))} communities, each with a three- or four-digit ID, and each still containing far more English tweets than French.

      Community detection will be discussed in greater detail below, though what is important for the moment is that these communities contained \num{\Sexpr{nrow(tweets)}} tokens of (lol).
      In this case, these were tokens of (lol) as a lexical variable and so included variants such as \lexi{rofl} \gloss{roll on the floor laughing} and even \lexi{mdr} from French \lexi{mort de rire}, the rough equivalent of \lexi{lol}.
      In other words, lexical items that are not of interest in the current study were included and spelling variants of \orth{lol} such as \orth{LOL} or \orth{lolol} were collapsed into tokens of one lexical item: \lexi{lol}.
      Fortunately, the original spellings were stored in the corpus, and by far the most common lexical item was \lexi{lol}, so filtering out unwanted lexical items resulted in a final corpus with \Sexpr{length(levels(factor(lol$Community)))} communities, \num{\Sexpr{nrow(lol)}} tokens of the orthographic variable (lol), and \Sexpr{length(levels(factor(lol$lol)))} spelling variants for (lol).

    \subsection{Coding}
      \label{subsec:coding}
      In order to perform a quantitative analysis on the use of (lol) in the present Twitter corpus, each token was coded for several different variables.
      The linguistic variable in this case, (lol), is made up of orthographic variants of what was originally an acronym standing for \gloss{laugh out loud}.
      Despite there being \Sexpr{length(variants)} variants in the data, only \Sexpr{length(variantsGT)} occurred more than 5 times, namely \orth{\Sexpr{variantsGT[1]}}, \orth{\Sexpr{variantsGT[2]}}, and \orth{\Sexpr{variantsGT[3]}}.
      Of special note when interpreting why particular orthographic variants appear is the presence of auto-complete and auto-correct systems on both smartphones and computers.
      For instance, the initial capital in \orth{Lol} could sometimes be forced by the typing device when at the beginning of a sentence as opposed to being something the user purposely did.
      The use of keylogging software that tracks key presses can identify whether auto-complete was used \parencite[e.g.,][p.~9]{schneier_digital_2021}, though this was not done for the present study.

      While this lack is distinction between what is auto-completed/auto-corrected and what is not could introduce a potentially significant methodological issue, there are two important reasons to believe that the issue is not a large one.
      First, auto-complete/auto-correct systems are sometimes generated by the typing habits of the user.
      If a user always manually types \orth{LOL}, their auto-correcting system may very well start correcting any spelling of (lol) to the fully capitalized variant.
      While this means the user's likelihood of varying their spelling is somewhat diminished, the spelling that is ultimately produced is at least representative of their own personal norm.
      Second, the most likely candidate for auto-correction is \orth{Lol} at the beginning of a sentence as this would be in adhering to the capitalization rules of standard English orthography, but this variant is easily the least frequent of the three top variants, as will be evident in the \nameref{sec:results} section below.

      Beyond the linguistic variable, there are both social and pragmatic variables for which each token of (lol) was coded.
      The former will be covered in section \ref{subsubsec:social_vars} and the latter in section \ref{subsubsec:pragmatic_vars}.

      \subsubsection{Social variables}
        \label{subsubsec:social_vars}
        It has been well established that social variables are meaningful for language variation in CMC.
        For instance, \textcite{danescu-niculescu-mizil_mark_2011} found that Twitter users accommodate their language styles relative to their interlocutors, both symmetrically and asymmetrically (pp.~6-8).
        As the literature on accommodation theory suggests that accommodation is triggered not just by a need for ``communicational efficiency'', but also to gain social approval and maintain one's identity \parencite[p.~3]{danescu-niculescu-mizil_mark_2011}, this suggests that social factors are unsurprisingly at work on social media.

        CMC presents challenges for obtaining social descriptors for locutors in a corpus that are not present in data that was obtained through traditional sociolinguistic interviews as researchers do not always interact directly with those producing data in CMC studies, as is the case in the current study.
        This is particularly true when large corpora are collected, which is often the case in CMC research.
        For instance, \textcite{ilbury_sassy_2020} targeted openly gay men from the south of England in his study of Twitter, but he analyzed a only ten users as opposed to the \Sexpr{length(unique(lol$User))} users in my corpous.
        This small number of users allowed Ilbury to conduct a sort of virtual ethnography to establish the identities of those he analyzed even though he never interacted with them directly.

        Similarly, \textcite{jones_toward_2015} also faced the challenge of determining if the users of Twitter that he examined were indeed native speakers of African-American Vernacular English (AAVE) or if they were simply performing an identity.
        He dealt with this problem much like Ilbury did: through ethnography \parencite[p.~412]{jones_toward_2015}.
        However, and perhaps because his data was much more large scale than Ilbury's, Jones's ethnography included experience with African-Americans in person, and his goal was not to identify African-Americans on Twitter but to identify native speakers of AAVE who may not necessarily be African-American.

        Gender has also found its way into CMC research on Twitter.
        \textcite{bamman_gender_2014} deduced users' genders by establishing gender associations for given names using US census data in which the majority gender for a name in the census data would be taken as the typical gender for people with that name (p.~140).
        While most names had a clear association using this method, and while most people did not have names that were highly ambiguous, there is still a level of uncertainty with classifying users this way, just as there is for race, ethnicity, and sexual orientation.
        For this reason, I focus on social variables that are more directly observable on Twitter, namely community membership and centrality in a community as calculated using well established social network analysis techniques as well as geographic location as given by the user.

        \paragraph{Concepts of community}
          \label{para:concepts_of_community}
          Perhaps the two most common ways to conceptualize communities in variationist research is through the concepts of speech communities and communities of practice.
          The former are defined primarily according to shared linguistic norms and linguistic evaluations among people in a relatively clearly delineated geographic area.
          This concept of community has been employed since \textcite{labov_social_2006} proposed it in his foundational work in sociolinguistics
          The latter came to prominence in the work of Eckert and gives precedence to what draws people together, that being a shared activity.
          With communities of practice, smaller scale communities are typically identified and so the importance of geography is not necessarily as present as it typically is for speech communities.
          The key is simply that there is a shared activity, which implies sharing physical space, as well, but that is no longer required as people can partake in shared activities virtually with the advent of the internet.

          Various concepts of community have thus been used in CMC research.
          Castells (2000) defined communities along similar lines as communities of practice where they are ``organized around a shared interest or purpose,'' but he did not think these were the same as face-to-face communities because of the differences in how interaction occurs.
          Castells (2000) referred to these communities as virtual communities \parencite[as cited in][p.~283]{auer_style_2008}.
          \textcite{auer_style_2008}, for his part, recognized that the connections between members of these communities could be quite literal through the user of hyperlinks (pp.~283-284), which is indeed a feature that is not possible in face-to-face communities.

          What is at least implicit in all these concepts is the idea of interaction, which is how I define communities for the present study.
          Those who interact with each other more than with others may be considered as members of the same community.
          Formally, this can be quantified using community detection methods from social network analysis, one of which I will now describe.

        \paragraph{Community detection}
          \label{para:community_detection}
          One important area of development in modern social network analysis techniques that has been generally missing from sociolinguistics is community detection.
          Community detection is the process of using algorithms to delineate communities within a social network.
          In this case, a community is conceptualized as a cluster of individuals who interact with each other more than they do with others.
          For instance, Figure \ref{fig:example} shows a very simple hypothetical network consisting of Joe, Kelly, Bob, and Ted.
          In the network, Joe, Kelly, and Bob all know each other, but the only person who knows Ted is Bob.
          As a result, Joe, Kelly, and Bob likely form community of which Bob is not a part.
          Each of these connections is called a tie, but what may constitute a tie or how to quantify the strength of a tie is decided by the researcher.
          In the case of the present study, I define a tie existing betweeen two users if there is any directed tweet sent between them and the strength of that tie as the number of directed tweets between them.

          \begin{figure}[tbhp]
            \caption{Simple example network}
            \label{fig:example}
            <<example_community>>=
            @
          \end{figure}

          At the core of any tie is the idea that two people who are tied together interact with each other on some level so that ultimately any community in a social network is based on mutual interactions.
          This conceptualization of what a community is, a group of people who interact with each other, accords with conceptions of communities such as communities of practice.
          To share an activity together is inextricably about interacting with one another.
          For this reason, \textcite{schenkel_theorizing_2002} argued that social network analysis can be used to quantify the characteristics of communities of practice as the latter are more often identified through qualitative means.
          I take no stance on what draws people into their communities here, though, as is at least implicitly done with communities of practice as they suggest that the activity is what binds the community together.

          There are a number of algorithms for community detection, but the one used for this study comes from \textcite{blondel_fast_2008} and is commonly referred to as the Louvain method.
          The general mechanics of the Louvain method involve trying out different possible community divisions and calculating the modularity $Q$ for each pass in order to find the division that yields the highest $Q$.
          $Q$ itself is ``a measure of the quality of a particular division of a network'' \parencite{newman_finding_2004}.

          A standard test for the reliability of community detection algorithms is to apply them to \citeauthor{zachary_information_1977}'s (\citeyear{zachary_information_1977}) karate club data.
          This data includes a karate club that dissolved into two separate clubs, thus two explicitly different communities.
          An algorithm which takes the same network and divides it into the same two communities is thought to be valid and reliable.
          \textcite{newman_finding_2004} evaluated $Q$ itself for this using several $Q$ maximization algorithms and obtained good results, suggesting that this is indeed a useful measure.
          For the Louvain method specifically, \textcite{waltman_smart_2013} tested it on the karate club data and found it to be almost perfect at finding the maximum $Q$ possible (p.~471), suggesting that it is a reliable modularity optimization algorithm.

          As for the application of the Louvain method for community detection to sociolinguistic data, this has only been done once, to my knowledge.
          In \textcite{mcneill_lol_2018}, which used the same corpus as the present study, the lexical variable (lol) was found to be significantly constrained by the community to which one belonged.
          The variants in that study were English-origin and French-origin equivalents of \lexi{lol} as used within what could generally be considered French-language tweets.
          While there have not been other applications of community detection in sociolinguistic research, this result combined with its history of evaluation in sociology and computer science point to its validity.

          The implementation of the Louvain method used here comes from the social network analysis software Gephi \parencite{bastian_gephi:_2009}.
          Gephi uses a slightly modified version of the algorithm made to handle directed networks as opposed to the original version, which handled only undirected networks.
          This was more appropriate for the Twitter corpus used here as users do not always respond to directed tweets, making some ties asymmetric.
          The resolution option for the algorithm was kept at the default of 1.

          Initially, 8,945 communities were detected in the data, but as the goal at the time of the original study involved looking at those who might be considered French speakers specifically, only communities which contained tweets with French in them were analyzed, resulting in \Sexpr{length(levels(factor(tweets$Community)))} communities, each with a three- or four-digit ID.

          These \Sexpr{length(levels(factor(tweets$Community)))} communities contained \num{\Sexpr{nrow(tweets)}} tokens of (lol).
          In this case, these were tokens of (lol) as a lexical variable and so included variants such as \lexi{rofl} \gloss{roll on the floor laughing} and even \lexi{mdr} from French \lexi{mort de rire}, the rough equivalent of \lexi{lol}.
          In other words, lexical items that are not of interest in the current study were included and spelling variants of \orth{lol} such as \orth{LOL} or \orth{lolol} were collapsed into tokens of one lexical item: \lexi{lol}.
          Fortunately, the original spellings were stored in the corpus, and by far the most common lexical item was \lexi{lol}, so filtering out unwanted lexical items resulting in a corpus with \Sexpr{length(levels(factor(lol$Community)))} communities, \num{\Sexpr{nrow(lol)}} tokens of the orthographic variable (lol), and \Sexpr{length(levels(factor(lol$lol)))} spelling variants for (lol).

        \paragraph{Centrality measures}
          \label{para:centralirty_measures}
          In social network analysis, a centrality measure is a measure of a person's position within a given community.
          In the perhaps more familiar terms of communities of practice, this is somewhat similar to deciding which members are core members and which are peripheral members.
          However, centrality measures are always quantitative, as the name implies.

          CMC research has included centrality measures at least as far back as \textcite{paolillo_virtual_1999} in his study of an IRC community.
          They have also been used in analyzing language on German hip-hop web sites \parencite{auer_style_2008} and on Twitter using follower count \parencite{danescu-niculescu-mizil_mark_2011}.
          Centrality has often, though not always, been found to be significant in these studies.

          Likewise, centrality measures have been used in language variation studies since \textcite{milroy_language_1987}.
          Just as \textcite{milroy_language_1987} did, the implementation in sociolinguistics tends to involve the use of an index with a relatively small scale of possible values, such as 5.
          Part of the reason for this approach is that it can be exceedingly difficult to track face-to-face interactions, which is conversely not a problem at all with Twitter data as directed tweets are explicit.

          There are many other centrality measures, as well, though the one used in this study is PageRank \parencite{brin_anatomy_1998}, which was calculated for each user in the data relative to the community of which they were a member.
          PageRank was originally developed for ordering search engine results and ultimately led to the creation of Google.
          Equation \ref{eq:pagerank} shows how page $A$'s PageRank $PR$, or in this case person $A$'s $PR$, is calculated.
          \begin{equation}
            \label{eq:pagerank}
            PR \left( A \right) = \left( 1 - d \right) + d \left( \frac{PR \left( T1 \right)}{C \left( T1 \right)} + ... + \frac{PR \left( Tn \right)}{C \left( Tn \right)} \right)
          \end{equation}
          Here, $d$ is a damping factor between zero and one, $Tn$ is a page that links to page $A$, and $C(Tn)$ is the total pages linked to by page $Tn$.
          This effectively makes PageRank a function of the number of pages that link to the page of interest as well as the PageRanks of those pages.
          As a result, a user who directs many tweets to other members of their community but who receives very few tweets from other members will not have a particularly high PageRank.
          The intuition is that it is not difficult to talk a lot, but it is difficult to get people to care enough about what a person thinks to bother talking to that person.

        \paragraph{Geographic location}
          \label{para:geographic_location}
          Geographic location has also proved to be a meaningful social variable for language variation on Twitter, despite Twitter not be regionally segregated.
          It is possible to for users to search for tweets that are emanating from a particular physical area, but this is not the default setting nor do a user's followed accounts necessarily come from their own region.
          However, geographic variation has been found at least for AAVE features \parencite{eisenstein_phonological_2013, jones_toward_2015} and lexical variables \parencite{huang_understanding_2016}.
          Part of this importance may be due to a propensity for Twitter users to form virtual communities with those from the same regions despite this not being necessary, as there as at least some evidence that this sort of agglomeration happens \parencite[pp.~88-91]{mcneill_lol_2018}.

          Geographic location is also a social variable that is fairly easy to obtain for users of Twitter, though there are some caveats.
          The simplest way to get this information, and what is was done for the present study, is to use the location that each user entered manually in their profile.
          This is often available and also returned by the Twitter API when tweets are collected.
          The downside to this is naturally that users can enter any location that they want regardless of accuracy, thus an assumption that only a small number of users enter inaccurate locations is required.

          An alternative approach to finding the geographic locations of users is to use geotags.
          Twitter users can turn on this feature so that, when they send a tweet, the exact location they sent it from will be stored as metadata with said tweet.
          However, this feature is rarely used.
          \textcite{jones_toward_2015} found only 150 to 800 geotagged tweets per lexical item in his study, which accounted for between 2.5\% and 7.0\% of the tweets containing those lexical items (p.~407).
          Using this method calls for an API access level that makes amassing extremely large corpora possible, which was out of reach for the current study.
          For example, \textcite{huang_understanding_2016} used geotagging but were also able to collect 924 million such tweets over the course of a year with the access level that they had (p.~244).
          As a result, manually entered geographic locations are used for the present study.

      \subsubsection{Pragmatic variables}
        \label{subsubsec:pragmatic_vars}
        As was discussed in section \ref{subsec:previous_lol}, a repeated argument for (lol) as a lexical variable and orthographic variables in general is that they are used for pragmatic effects.
        One of the difficulties for performing the sort of discourse analyses that could uncover such effects is that long and/or repeated conversations between pairs of individuals on Twitter are not easily obtained.
        \textcite{danescu-niculescu-mizil_mark_2011} solved this problem by identifying pairs of users who were likely to converse often and mining each of their entire Twitter histories.
        With both histories at hand, it was possible to reconstruct repeated, long conversations between the pairs \parencite[p.~3]{danescu-niculescu-mizil_mark_2011}.
        Such a solution was not achievable given the resources of the current study, so I chose not to perform an exhaustive discourse analysis for pragmatic factors.

        What can be analyzed in a quantitative fashion that could also shed light on some pragmatic factors that are linked to the orthographic variation of (lol) is the sentiment of each turn.
        In this case, a turn is conceived of as a single tweet, which may or may not be multiple sentences but is always limited to 140 characters.
        The sentiment classifier R package sentimentr \parencite{rinker_sentimentr_2019} was used to calculate the polarity sentiment of each turn.
        No preprosessing of the corpus was done before sending it to this classifier, though the dictionary used by the classifier was checked to ensure that it did not contain \lexi{lol} itself as a lexical item.

    \subsection{Statistics}
      \label{subsec:statistics}
      The data analyzed in this study is all categorical, and the typical descriptive statistics for categorical data are used.
      One such statistic that is worth discussing as it does not appear in sociolinguistic research a great deal is the measure of dispersion for variants of (lol) for either an individual or a community.
      The Simpson diversity index $D$ \parencite{simpson_measurement_1949}, as described in equation \ref{eq:simpson}, is used as a measure of stability in the sense that a small dispersion can be interpreted as a consistent preference for a particular variant whereas a large dispersion can be interpreted as a lack of clear preference for any particular variant.
      This ia rather novel use for $D$ in variationist studies where it otherwise shows up as a measure of language ecology \parencite[e.g.,][]{greenberg_measurement_1956} or as a measure of the diversity of interactions one has \parencite[e.g.,][]{sharma_style_2011}.
      \begin{equation}
        \label{eq:simpson}
        D = 1 - \sum_{i=1}^R{p_{i}^2}
      \end{equation}

      In equation \ref{eq:simpson}, $p$ is the relative frequency of a variant $i$ of the variable in question.
      Essentially, the few variants included and the greater the frequency of the mode relative to the other variants, the lower $D$ will be.
      One can imagine a uniform distribution as having a very high $D$ and a strongly unimodal distribution having a very low $D$.

  \section{Results}
    \label{sec:results}
    The research question for this study asked what the social and/or pragmatic constraints are for the realization of the orthographic variable (lol).
    In terms of social constraints, section \ref{subsec:social_constraints} specifically looks at how detected communities differ, how provinces differ, and how a Twitter user's centrality within their detected community impacts their realizations of (lol).
    For pragmatic constraints, section \ref{subsec:pragmatic_constraints} looks into possible relationships between (lol) and the sentiment of a tweet.

    \subsection{Social constraints}
      \label{subsec:social_constraints}
      The summary of the characteristics for each community, shown in Table \ref{tab:summary_communities} reveal a general lack of variation in the mode of each community but internal variation in the variants used.
      The mode for every community is \orth{lol} except community \Sexpr{communitiesSummary[12, "Community"]} with all uppercase \orth{\Sexpr{communitiesSummary[12, "Mode"]}} as the mode.
      The diversity measures, however, suggest that \orth{lol} is far from being the exclusive variants used, with a median of diversity of \Sexpr{round(median(communitiesSummary$Diversity), 2)} among the communities.
      The only communities to be highly consistent in which using a single variant are communities \Sexpr{communitiesSummary[5, "Community"]} and \Sexpr{communitiesSummary[11, "Community"]} which each use the \orth{lol} spelling at all times.
      However, (lol) was rarely used in these two communities to begin with as only \Sexpr{length(unique(lol[lol$Community == "799",]$User))} and \Sexpr{length(unique(lol[lol$Community == "2067",]$User))} members produced (lol) at all in each, respectively.
      Communities \Sexpr{communitiesSummary[5, "Community"]} and \Sexpr{communitiesSummary[11, "Community"]} can therefore not be taken as evidence that (lol) would be invariant even within said communities save for the unlikely scenario where a larger sample would not uncover more tokens.
      \begin{table}[tbhp]
        \centering
        \caption{Summary statistics for each community}
        \label{tab:summary_communities}
        \begin{tabular}{l l r r}
          Community                                  & Mode                                  & Diversity                                            & Members \rule{0pt}{14pt} \\
          \hline
          \Sexpr{communitiesSummary[1, "Community"]} & \Sexpr{communitiesSummary[1, "Mode"]} & \Sexpr{round(communitiesSummary[1, "Diversity"], 2)} & \Sexpr{communitiesSummary[1, "Size"]} \\
          \Sexpr{communitiesSummary[2, "Community"]} & \Sexpr{communitiesSummary[2, "Mode"]} & \Sexpr{round(communitiesSummary[2, "Diversity"], 2)} & \Sexpr{communitiesSummary[2, "Size"]} \\
          \Sexpr{communitiesSummary[3, "Community"]} & \Sexpr{communitiesSummary[3, "Mode"]} & \Sexpr{round(communitiesSummary[3, "Diversity"], 2)} & \Sexpr{communitiesSummary[3, "Size"]} \\
          \Sexpr{communitiesSummary[4, "Community"]} & \Sexpr{communitiesSummary[4, "Mode"]} & \Sexpr{round(communitiesSummary[4, "Diversity"], 2)} & \Sexpr{communitiesSummary[4, "Size"]} \\
          \Sexpr{communitiesSummary[5, "Community"]} & \Sexpr{communitiesSummary[5, "Mode"]} & \Sexpr{round(communitiesSummary[5, "Diversity"], 2)} & \Sexpr{communitiesSummary[5, "Size"]} \\
          \Sexpr{communitiesSummary[6, "Community"]} & \Sexpr{communitiesSummary[6, "Mode"]} & \Sexpr{round(communitiesSummary[6, "Diversity"], 2)} & \Sexpr{communitiesSummary[6, "Size"]} \\
          \Sexpr{communitiesSummary[7, "Community"]} & \Sexpr{communitiesSummary[7, "Mode"]} & \Sexpr{round(communitiesSummary[7, "Diversity"], 2)} & \Sexpr{communitiesSummary[7, "Size"]} \\
          \Sexpr{communitiesSummary[8, "Community"]} & \Sexpr{communitiesSummary[8, "Mode"]} & \Sexpr{round(communitiesSummary[8, "Diversity"], 2)} & \Sexpr{communitiesSummary[8, "Size"]} \\
          \Sexpr{communitiesSummary[9, "Community"]} & \Sexpr{communitiesSummary[9, "Mode"]} & \Sexpr{round(communitiesSummary[9, "Diversity"], 2)} & \Sexpr{communitiesSummary[9, "Size"]} \\
          \Sexpr{communitiesSummary[10, "Community"]} & \Sexpr{communitiesSummary[10, "Mode"]} & \Sexpr{round(communitiesSummary[10, "Diversity"], 2)} & \Sexpr{communitiesSummary[10, "Size"]} \\
          \Sexpr{communitiesSummary[11, "Community"]} & \Sexpr{communitiesSummary[11, "Mode"]} & \Sexpr{round(communitiesSummary[11, "Diversity"], 2)} & \Sexpr{communitiesSummary[11, "Size"]} \\
          \Sexpr{communitiesSummary[12, "Community"]} & \Sexpr{communitiesSummary[12, "Mode"]} & \Sexpr{round(communitiesSummary[12, "Diversity"], 2)} & \Sexpr{communitiesSummary[12, "Size"]} \\
          \Sexpr{communitiesSummary[13, "Community"]} & \Sexpr{communitiesSummary[13, "Mode"]} & \Sexpr{round(communitiesSummary[13, "Diversity"], 2)} & \Sexpr{communitiesSummary[13, "Size"]} \\
        \end{tabular}
      \end{table}

      The only community to not have \orth{lol} as its mode was community 2265, which had \orth{LOL} as its mode instead.
      Table \ref{tab:summary_2265} provides summary statistics for each user in this community.
      What is immediately apparent is that the mode for this community stems mostly from Jesus Ibarra's linguistic behavior in that they produced far more tokens of (lol) than anyone else and were also quite consistent in their spelling with a diversity of \Sexpr{round(usersSummary2265[2, "Diversity"], 2)}.
      It is not clear what this community's linguistic behavior relative to (lol) would look like given a larger sample size.
      As it stands, it is difficult to take results for community 2265 as evidence for or against a difference in norms for (lol) between communities.
      \begin{table}[tbhp]
        \centering
        \caption{Summary statistics for community 2265}
        \label{tab:summary_2265}
        \begin{tabular}{l r l r r}
          User                                & PageRank                                          & Mode                                & Diversity                                          & Tokens \rule{0pt}{14pt} \\
          \hline
          \Sexpr{usersSummary2265[1, "User"]} & \Sexpr{round(usersSummary2265[1, "PageRank"], 4)} & \Sexpr{usersSummary2265[1, "Mode"]} & \Sexpr{round(usersSummary2265[1, "Diversity"], 2)} & \Sexpr{usersSummary2265[1, "Tokens"]} \\
          \Sexpr{usersSummary2265[2, "User"]} & \Sexpr{round(usersSummary2265[2, "PageRank"], 4)} & \Sexpr{usersSummary2265[2, "Mode"]} & \Sexpr{round(usersSummary2265[2, "Diversity"], 2)} & \Sexpr{usersSummary2265[2, "Tokens"]} \\
          \Sexpr{usersSummary2265[3, "User"]} & \Sexpr{round(usersSummary2265[3, "PageRank"], 4)} & \Sexpr{usersSummary2265[3, "Mode"]} & \Sexpr{round(usersSummary2265[3, "Diversity"], 2)} & \Sexpr{usersSummary2265[3, "Tokens"]} \\
          \Sexpr{usersSummary2265[4, "User"]} & \Sexpr{round(usersSummary2265[4, "PageRank"], 4)} & \Sexpr{usersSummary2265[4, "Mode"]} & \Sexpr{round(usersSummary2265[4, "Diversity"], 2)} & \Sexpr{usersSummary2265[4, "Tokens"]} \\
          \Sexpr{usersSummary2265[5, "User"]} & \Sexpr{round(usersSummary2265[5, "PageRank"], 4)} & \Sexpr{usersSummary2265[5, "Mode"]} & \Sexpr{round(usersSummary2265[5, "Diversity"], 2)} & \Sexpr{usersSummary2265[5, "Tokens"]} \\
          \Sexpr{usersSummary2265[6, "User"]} & \Sexpr{round(usersSummary2265[6, "PageRank"], 4)} & \Sexpr{usersSummary2265[6, "Mode"]} & \Sexpr{round(usersSummary2265[6, "Diversity"], 2)} & \Sexpr{usersSummary2265[6, "Tokens"]} \\
          \Sexpr{usersSummary2265[7, "User"]} & \Sexpr{round(usersSummary2265[7, "PageRank"], 4)} & \Sexpr{usersSummary2265[7, "Mode"]} & \Sexpr{round(usersSummary2265[7, "Diversity"], 2)} & \Sexpr{usersSummary2265[7, "Tokens"]} \\
          \Sexpr{usersSummary2265[8, "User"]} & \Sexpr{round(usersSummary2265[8, "PageRank"], 4)} & \Sexpr{usersSummary2265[8, "Mode"]} & \Sexpr{round(usersSummary2265[8, "Diversity"], 2)} & \Sexpr{usersSummary2265[8, "Tokens"]} \\
        \end{tabular}
      \end{table}

      It is quite possible that the distributions for (lol) in each community are not significantly different.
      To test this null hypothesis, Fisher's exact test was used.
      A $\chi^2$-test was not appropriate given the low expected counts for some cells in the relevant contingency table.
      The null hypothesis that the distribution of (lol) for each community was the same was rejected ($P < \Sexpr{round_any(lolSigTests$Community$Test$p.value, 0.05, f = ceiling)}$).
      Using Cramér's $V$ to measure the effect size returned a value of \Sexpr{round(lolSigTests$Community$Effect, 2)}, a generally small effect size suggesting that the differences were not great.
      The large number of variants and communities makes displaying a contingency table of the results here both difficult and uninformative, but the proportions for the \orth{lol} variant range from 75.8\% in community 756 to 52.5\% in community 1032, though most were had proportions near 70.0\%. % Manually checked prop.table
      Thus, while the dominance of the \orth{lol} variant in almost every community does vary, and while the distributions for (lol) are not identical, the differences are not great.
      It would be difficult to argue that the spelling of (lol) varies enough from community to community to make it maleable as a marker of one's social identity.

      Similarly, Table \ref{tab:summary_provinces} presents a summary of (lol) usage relative to the province of the Twitter user.
      While modes other than \orth{lol} appear, this happens only where the number of residents using (lol) is limited to one to three people and so hardly represents what would be produced if a larger sample were taken.
      In all other provinces, \orth{lol} was always the most frequent variant.
      Also, as with community, the null hypothesis that the distribution of (lol) for each province was the same was rejected ($P < \Sexpr{round_any(lolSigTests$Province$Test$p.value, 0.05, f = ceiling)}$), though in this case the effect size was even smaller than for community ($V \approx \Sexpr{round(lolSigTests$Province$Effect, 2)}$).
      In this case, even less evidence can be found that (lol) is an socially meaningful.
      There are indeed some differences between the provinces, but nothing great enough to indicate that Twitter users express their provincial identities through the spelling of (lol).

      \begin{table}[tbhp]
        \centering
        \caption{Summary statistics for each province}
        \label{tab:summary_provinces}
        \begin{tabular}{l l r r}
          Province                                   & Mode                                  & Diversity                                            & Residents using (lol) \rule{0pt}{14pt} \\
          \hline
          \Sexpr{provincesSummary[1, "Province"]} & \Sexpr{provincesSummary[1, "Mode"]} & \Sexpr{round(provincesSummary[1, "Diversity"], 2)} & \Sexpr{provincesSummary[1, "Size"]} \\
          \Sexpr{provincesSummary[2, "Province"]} & \Sexpr{provincesSummary[2, "Mode"]} & \Sexpr{round(provincesSummary[2, "Diversity"], 2)} & \Sexpr{provincesSummary[2, "Size"]} \\
          \Sexpr{provincesSummary[3, "Province"]} & \Sexpr{provincesSummary[3, "Mode"]} & \Sexpr{round(provincesSummary[3, "Diversity"], 2)} & \Sexpr{provincesSummary[3, "Size"]} \\
          \Sexpr{provincesSummary[4, "Province"]} & \Sexpr{provincesSummary[4, "Mode"]} & \Sexpr{round(provincesSummary[4, "Diversity"], 2)} & \Sexpr{provincesSummary[4, "Size"]} \\
          \Sexpr{provincesSummary[5, "Province"]} & \Sexpr{provincesSummary[5, "Mode"]} & \Sexpr{round(provincesSummary[5, "Diversity"], 2)} & \Sexpr{provincesSummary[5, "Size"]} \\
          \Sexpr{provincesSummary[6, "Province"]} & \Sexpr{provincesSummary[6, "Mode"]} & \Sexpr{round(provincesSummary[6, "Diversity"], 2)} & \Sexpr{provincesSummary[6, "Size"]} \\
          \Sexpr{provincesSummary[7, "Province"]} & \Sexpr{provincesSummary[7, "Mode"]} & \Sexpr{round(provincesSummary[7, "Diversity"], 2)} & \Sexpr{provincesSummary[7, "Size"]} \\
          \Sexpr{provincesSummary[8, "Province"]} & \Sexpr{provincesSummary[8, "Mode"]} & \Sexpr{round(provincesSummary[8, "Diversity"], 2)} & \Sexpr{provincesSummary[8, "Size"]} \\
          \Sexpr{provincesSummary[9, "Province"]} & \Sexpr{provincesSummary[9, "Mode"]} & \Sexpr{round(provincesSummary[9, "Diversity"], 2)} & \Sexpr{provincesSummary[9, "Size"]} \\
          \Sexpr{provincesSummary[10, "Province"]} & \Sexpr{provincesSummary[10, "Mode"]} & \Sexpr{round(provincesSummary[10, "Diversity"], 2)} & \Sexpr{provincesSummary[10, "Size"]} \\
          \Sexpr{provincesSummary[11, "Province"]} & \Sexpr{provincesSummary[11, "Mode"]} & \Sexpr{round(provincesSummary[11, "Diversity"], 2)} & \Sexpr{provincesSummary[11, "Size"]} \\
          \Sexpr{provincesSummary[12, "Province"]} & \Sexpr{provincesSummary[12, "Mode"]} & \Sexpr{round(provincesSummary[12, "Diversity"], 2)} & \Sexpr{provincesSummary[12, "Size"]} \\
          \Sexpr{provincesSummary[13, "Province"]} & \Sexpr{provincesSummary[13, "Mode"]} & \Sexpr{round(provincesSummary[13, "Diversity"], 2)} & \Sexpr{provincesSummary[13, "Size"]} \\
          \Sexpr{provincesSummary[14, "Province"]} & \Sexpr{provincesSummary[14, "Mode"]} & \Sexpr{round(provincesSummary[14, "Diversity"], 2)} & \Sexpr{provincesSummary[14, "Size"]} \\
        \end{tabular}
      \end{table}

      Another way to approach the question of whether (lol) is socially conditioned is to look at individuals relative to their communities.
      While communities may have clear norms that differ little from each other, this does not mean that all speakers follow these norms.
      Indeed, out of the \Sexpr{nrow(usersSummaryActive)} active producers of (lol) in the data, defined as those producing at least 10 tokens, \Sexpr{nrow(usersSummaryActive[usersSummaryActive$Mode != "lol" & usersSummaryActive$Community != "2265",])} who belong to \orth{lol} dominant communities use another variant most frequently, namely \orth{LOL} or \orth{Lol}.
      Additionally, all of these users other than Ambria Howard are above the 64th percentile for PageRanks in their communities, meaning they are fairly central members of their communities.
      Ambria is an outlier with a PageRank percentile of \Sexpr{round(usersSummaryActive[usersSummaryActive$User == "Ambria Howard", "PR_Percentile"], 2)}, making this user rather peripheral to their community.
      This suggests that individuals do in fact go against the norms of their community and that those individuals who do so are generally those who have a central position in their community.

      % Table with a few exempliar individuals

      In this sense, (lol) is indeed socially variable, though it is clearly not indexing any particular community.
      The motivation for why these central community members buck the norms of their communities would likely require a discourse analysis that is beyond the scope of the present study but would perhaps be an interesting avenue for future research.

    \subsection{Pragmatic constraints}
      \label{subsec:pragmatic_constraints}
      While some small amount of the variation in (lol) may be explained by a handful of users going against the norms of their communities, it would be difficult to argue that (lol) is primarily conditioned by how users express their social identities.
      Another possibility is that variations in the spelling of (lol) are used for pragmatic effect.
      One such possibility explored here was the relationship between the variant of (lol) used and the sentiment of the tweet.
      The assumption is that, if different spellings are associated with different sentiments, there is some sort of pragmatic work being done by those particular spellings.
      This work could be boosting the sentiment in the same positive or negative direction that the rest of the tweet suggested.
      Alternatively, the spelling may be doing the opposite, softening a negative tweet or adding mockery to a positive tweet.
      These nuances would be best explored through a thorough discourse analysis, which is beyond the scope of this study, but the quantitative results here are indicative of whether that is a worthwhile avenue for future research.

      Among all the variants of (lol), three were exponentially more frequent: \orth{lol}, \orth{LOL}, and \orth{Lol}.
      The sentiments for tweets containing only these three variants were thus analyzed.
      Additionally, tweets that received sentiments of zero were excluded.
      Figure \ref{fig:sentiment_lol_hist} shows the distribution of sentiments for each of the major variants of (lol) where \orth{lol} has a mean of \Sexpr{round(as.numeric(lolSentMeans["lol"]), 3)}, \orth{Lol} a mean of \Sexpr{round(as.numeric(lolSentMeans["Lol"]), 3)}, and \orth{LOL} a mean of \Sexpr{round(as.numeric(lolSentMeans["LOL"]), 3)}.
      \begin{figure}[tbhp]
        \centering
        \caption{Density plots for the sentiments of tweets for each of the three major variants of (lol)}
        \label{fig:sentiment_lol_hist}
        <<sentiment_lol_hist>>=
        @
      \end{figure}

      All three variants have positive sentiment means, though they are not much above the neutral sentiment of zero.
      Relative to each other, the two version containing capitalization do appear to be different from \orth{lol} in that they are more positive.
      Indeed, a one-way ANOVA for the difference in means shows this difference to be statistically significant ($P < \Sexpr{round_any(lolSentSigTestSummary[[1]][["Pr(>F)"]][[1]], 0.05, f = ceiling)}$).
      While this does suggest that some amount of pragmatic work is being done by the different variants of (lol) in relation to sentiment, the amount is seemingly very small.
      If (lol) is in fact pragmatically conditioned to a great extent, it is unlikely that this will be found by looking at sentiment.
      Indeed, one of the sentiment dictionaries available in the sentimentr classifier package includes \lexi{lol} with a corresponding sentiment of \Sexpr{lexicon::hash_sentiment_senticnet[x == "lol", "y"]} \parencite{cambria_senticnet_2016}.
      Out of the \num{\Sexpr{nrow(lexicon::hash_sentiment_senticnet)}} lexical items in this dictionary, \num{\Sexpr{nrow(lexicon::hash_sentiment_senticnet[y > 0.111])}} have higher sentiments, most of which are at least twice as high as \lexi{lol}, meaning that a large proportion of lexical items are assumed to have a much larger impact on sentiment than \lexi{lol}.
      As others have claimed, a more fruitful direction may be to look into its behavior as a ``phatic filler'' (see section \ref{subsubsec:lexical_lol}).

  \section{Discussion}
    \label{sec:discussion}
    The goal of this study has been to search for possible social and/or pragmatic constraints on the realization of the orthographic variable (lol).
    The methods used have been quantitative and so work well for uncovering aggregate group patterns.
    However, while there is some evidence for such patterns, they are undoubtedly small.
    The distributions of realizations of (lol) do differ from community to community and province to province, yet the norm of lowercase \orth{lol} is shared by all groups.
    Variants of (lol) are also associated with positive sentiment tweets, but the sentiment polarities of said tweets are by and large only slightly above neutral.
    In both cases, however, there is evidence that a more qualitative discourse analysis would uncover both social and pragmatic functions for (lol).

    % Alexis Moore <Lol> because always sentence-initial except one token of <lol>
    % Aliyya el-Mowad <LOL> with a good amount of <lol>, always sentence-final, usually no final punctuation, seems to be indicating good humor
    % Ambria Howard <LOL> plenty <lol> and 2 <Lol> sentence-initially. Final punctuation variable. Seems to be indicating good humor

  \printbibliography
\end{document}
